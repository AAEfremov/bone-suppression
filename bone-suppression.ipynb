{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import dicom\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "from scipy.misc import imresize, imsave, imread\n",
    "from skimage import exposure \n",
    "from skimage.util import random_noise\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_extraction import image\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "import png\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import imreg_dft as ird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _tf_fspecial_gauss(size, sigma):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "\n",
    "    x = tf.constant(x_data, dtype=tf.float32)\n",
    "    y = tf.constant(y_data, dtype=tf.float32)\n",
    "\n",
    "    g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g / tf.reduce_sum(g)\n",
    "\n",
    "def tf_ssim(img1, img2, cs_map=False, mean_metric=True, size=11, sigma=1.5):\n",
    "    window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "    mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
    "    mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1],padding='VALID')\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
    "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
    "    sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
    "    if cs_map:\n",
    "        value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2)),\n",
    "                (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
    "    else:\n",
    "        value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if mean_metric:\n",
    "        value = tf.reduce_mean(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "def tf_ms_ssim(img1, img2, mean_metric=True, level=5):\n",
    "    weight = tf.constant([0.0448, 0.2856, 0.3001, 0.2363, 0.1333], dtype=tf.float32)\n",
    "    mssim = []\n",
    "    mcs = []\n",
    "    for l in range(level):\n",
    "        ssim_map, cs_map = tf_ssim(img1, img2, cs_map=True, mean_metric=False)\n",
    "        mssim.append(tf.reduce_mean(ssim_map))\n",
    "        mcs.append(tf.reduce_mean(cs_map))\n",
    "        filtered_im1 = tf.nn.avg_pool(img1, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "        filtered_im2 = tf.nn.avg_pool(img2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "        img1 = filtered_im1\n",
    "        img2 = filtered_im2\n",
    "\n",
    "    # list to tensor of dim D+1\n",
    "    mssim = tf.pack(mssim, axis=0)\n",
    "    mcs = tf.pack(mcs, axis=0)\n",
    "\n",
    "    value = (tf.reduce_prod(mcs[0:level-1]**weight[0:level-1])*\n",
    "                            (mssim[level-1]**weight[level-1]))\n",
    "\n",
    "    if mean_metric:\n",
    "        value = tf.reduce_mean(value)\n",
    "    return value\n",
    "\n",
    "def sobel_conv(images, dim=5):\n",
    "    sobel_x = tf.constant([\n",
    "            [1, 0, -2, 0, 1],\n",
    "            [4, 0, -8, 0, 4],\n",
    "            [6, 0, -12, 0, 6],\n",
    "            [4, 0, -8, 0, 4],\n",
    "            [1, 0, -2, 0, 1]\n",
    "        ], tf.float32)\n",
    "    sobel_x_filter = tf.reshape(sobel_x, [dim, dim, 1, 1])\n",
    "    sobel_y_filter = tf.transpose(sobel_x_filter, [1, 0, 2, 3])\n",
    "    \n",
    "    filtered_x = tf.nn.conv2d(images, sobel_x_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    filtered_y = tf.nn.conv2d(images, sobel_y_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    filtered = tf.sqrt(tf.pow(filtered_x, 2) + tf.pow(filtered_y, 2))\n",
    "    return filtered\n",
    "\n",
    "def extract_dicom(files):\n",
    "    images = []\n",
    "    # loop through all the DICOM files\n",
    "    for i, filenameDCM in enumerate(files):\n",
    "        print(\"step: \" + filenameDCM + \" \", i)\n",
    "        \n",
    "        # read the dcm file\n",
    "#         ds = dicom.read_file(filenameDCM)\n",
    "#         # store the raw image data\n",
    "#         images += [ds.pixel_array]\n",
    "\n",
    "        # read the jpg file\n",
    "        ds = cv2.imread(filenameDCM)\n",
    "        ds = cv2.cvtColor(ds, cv2.COLOR_BGR2GRAY)\n",
    "        images += [ds]\n",
    "    return images\n",
    "\n",
    "def extract_data(num = -1, extension=\"jpg\"):\n",
    "    PathDicom = [\n",
    "        \"/Users/user/Downloads/to_test/to_test\"\n",
    "    ]\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    \n",
    "    for path in PathDicom:\n",
    "        for dirName, subdirList, fileList in os.walk(path):\n",
    "            for filename in fileList:\n",
    "                if \".\" + extension in filename.lower():\n",
    "                    lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "    \n",
    "    num = min(len(lstFilesDCM), num)\n",
    "    if num == -1:\n",
    "        num = len(lstFilesDCM)\n",
    "    \n",
    "    images = extract_dicom(sorted(lstFilesDCM)[:num])\n",
    "    return images\n",
    "\n",
    "def crop_to_square(image, upsampling):\n",
    "    if image.shape[0] == image.shape[1]:\n",
    "        return image\n",
    "    if upsampling:\n",
    "        img = Image.fromarray(image)\n",
    "        target_side = max(img.size)\n",
    "        horizontal_padding = (target_side - img.size[0]) / 2\n",
    "        vertical_padding = (target_side - img.size[1]) / 2\n",
    "        start = [-horizontal_padding, -vertical_padding]\n",
    "        width = img.size[0] + horizontal_padding\n",
    "        height = img.size[1] + vertical_padding\n",
    "    else:\n",
    "#         img = Image.fromarray(image)\n",
    "        target_side = min(image.shape)\n",
    "        horizontal_padding = int((image.shape[0] - target_side) / 2)\n",
    "        vertical_padding = int((image.shape[1] - target_side) / 2)\n",
    "        start = [horizontal_padding, vertical_padding]\n",
    "        width = image.shape[0] - horizontal_padding\n",
    "        height = image.shape[1] - vertical_padding\n",
    "#         print(img.size, start, width, height)\n",
    "        return image[start[0]:width, start[1]:height]\n",
    "        \n",
    "    img = img.crop((start[0], start[1], width, height))\n",
    "    return np.array(img)\n",
    "\n",
    "def preprocess(images, upsampling=False):\n",
    "#     images = [im / (-1.) for im in images]\n",
    "#     images = [scale(im.astype(float), axis=0).astype('float32') for im in images]\n",
    "    images = [(im + abs(im.min())) / (im.max() + abs(im.min()))  for im in images]\n",
    "    return images\n",
    "\n",
    "def resize(images, size):\n",
    "    return [imresize(i, (size,size), \"lanczos\") for i in images]\n",
    "\n",
    "def crop(images, upsampling=False):\n",
    "    return [crop_to_square(im, upsampling=upsampling) for im in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Readings of Original and Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = extract_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 1024\n",
    "train = crop(images, upsampling='True')\n",
    "train = resize(train, size)\n",
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "print('Min: ' + min(train[0]))\n",
    "print('Max: ' + max(train[0]))\n",
    "print('Mean: ' + mean(train[0]))\n",
    "print('Std: ' + std(train[0]))\n",
    "imshow(train[0].reshape((size,size)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.reshape(train, (len(train), size, size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = np.reshape(train, (len(train), size, size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/user/Documents/bone-suppression/database/bs/processed/registered_orig_35'\n",
    "for i in range(len(trainX)):\n",
    "    # the template\n",
    "    im0 = trainX[i]\n",
    "    # the image to be transformed\n",
    "    im1 = imresize(trainY[i], im0.shape, 'lanczos')\n",
    "    result = ird.similarity(im0, im1, numiter=3)\n",
    "    imsave(path + '/x/bs_' + str(i) + '.jpg', trainX[i])\n",
    "    imsave(path + '/y/bs_' + str(i) + '.jpg', result['timg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "                    featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_whitening=False,\n",
    "                    rotation_range=5.,\n",
    "                    width_shift_range=0.08,\n",
    "                    height_shift_range=0.08,\n",
    "                    shear_range=0.06,\n",
    "                    zoom_range=0.08,\n",
    "                    channel_shift_range=0.2,\n",
    "                    fill_mode='constant',\n",
    "                    cval=0.,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=False,\n",
    "                    rescale=None)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 1\n",
    "image_datagen.fit(trainX, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = len(trainX)\n",
    "for seed in range(115):\n",
    "    x = image_datagen.flow(trainX, shuffle=True, seed=seed, \n",
    "        save_to_dir='/Users/user/Documents/bone-suppression/database/bs/processed/augmented_1024_/x/', \n",
    "        batch_size=batch_size)\n",
    "    y = image_datagen.flow(trainY, shuffle=True, seed=seed, \n",
    "        save_to_dir='/Users/user/Documents/bone-suppression/database/bs/processed/augmented_1024_/y/', \n",
    "        batch_size=batch_size)\n",
    "    _ = x.next()\n",
    "    _ = y.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_path_pattern = \"/home/theskyabove/resources/augmented_1024_4005/x/*.jpg\"\n",
    "y_path_pattern = \"/home/theskyabove/resources/augmented_1024_4005/y/*.jpg\"\n",
    "queue_capacity = 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Previously Serialized Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/theskyabove/resources/augmented_1024_4005/testX_bs_1024_py3.pckl', 'rb') as f:\n",
    "    testX = pickle.load(f) / 255\n",
    "with open('/home/theskyabove/resources/augmented_1024_4005/testY_bs_1024_py3.pckl', 'rb') as f:\n",
    "    testY = pickle.load(f) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE-like Model with Pooling as a Size-changing Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, size, size, 1])\n",
    "Y_clear = tf.placeholder(tf.float32, [None, size, size, 1])\n",
    "X_tensor = tf.reshape(X, [-1, size, size, 1])\n",
    "\n",
    "n_filters = [16, 32, 64]\n",
    "filter_sizes = [5, 5, 5]\n",
    "\n",
    "current_input = X_tensor\n",
    "n_input = 1\n",
    "\n",
    "Ws = []\n",
    "shapes = []\n",
    "\n",
    "for layer_i, n_output in enumerate(n_filters):\n",
    "    with tf.variable_scope(\"encoder/layer/{}\".format(layer_i)):\n",
    "        shapes.append(current_input.get_shape().as_list())\n",
    "        W = tf.get_variable(\n",
    "            name='W',\n",
    "            shape=[\n",
    "                filter_sizes[layer_i],\n",
    "                filter_sizes[layer_i],\n",
    "                n_input,\n",
    "                n_output],\n",
    "            initializer=tf.random_normal_initializer(mean=0.0, stddev=0.02))\n",
    "        h = tf.nn.conv2d(current_input, W,\n",
    "            strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv = tf.nn.relu(h)\n",
    "        current_input = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
    "        Ws.append(W)\n",
    "        n_input = n_output\n",
    "\n",
    "print(n_filters, filter_sizes, shapes, current_input.get_shape().as_list())\n",
    "Ws.reverse()\n",
    "shapes.reverse()\n",
    "n_filters.reverse()\n",
    "n_filters = n_filters[1:] + [1]\n",
    "print(n_filters, filter_sizes, shapes)\n",
    "\n",
    "for layer_i, shape in enumerate(shapes):\n",
    "    with tf.variable_scope(\"decoder/layer/{}\".format(layer_i)):\n",
    "        W = Ws[layer_i]\n",
    "        h = tf.nn.conv2d_transpose(current_input, W,\n",
    "            tf.pack([tf.shape(X)[0], shape[1], shape[2], shape[3]]),\n",
    "            strides=[1, 2, 2, 1], padding='SAME')\n",
    "        current_input = tf.nn.relu(h)\n",
    "        \n",
    "Y = current_input\n",
    "cost_2 = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(Y_clear, Y), 1))\n",
    "cost = 1 - tf_ms_ssim(Y_clear, Y)\n",
    "\n",
    "learning_rate = tf.Variable(initial_value=1e-2, trainable=False, dtype=tf.float32)\n",
    "alpha = 0.99\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(alpha*cost + (1 - alpha)*cost_2)\n",
    "\n",
    "arch_info = 'crs_ms-ssim_mse_mp_1024_16-32-64_5-5-5_0.99'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Pipeline for Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_jpg(filename_queue):\n",
    "    reader = tf.WholeFileReader()\n",
    "    key, record_string = reader.read(filename_queue)\n",
    "    path, image = reader.read(filename_queue)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)\n",
    "    image = image / 255\n",
    "    return image\n",
    "\n",
    "def input_pipeline(x_filenames, y_filenames, batch_size):\n",
    "    seed = np.random.random()    \n",
    "    x_filename_queue = tf.train.string_input_producer(x_filenames, seed=seed, capacity=queue_capacity)\n",
    "    y_filename_queue = tf.train.string_input_producer(y_filenames, seed=seed, capacity=queue_capacity)\n",
    "    x_image = read_jpg(x_filename_queue)\n",
    "    y_image = read_jpg(y_filename_queue)\n",
    "    \n",
    "    min_after_dequeue = 4000\n",
    "    num_threads = 2\n",
    "    capacity = min_after_dequeue + (num_threads + 2) * 256\n",
    "    batch = tf.train.shuffle_batch(\n",
    "        [x_image, y_image], \n",
    "        batch_size=batch_size, \n",
    "        capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue, \n",
    "        num_threads=num_threads,\n",
    "        shapes=((size, size, 1), (size, size, 1)))\n",
    "    return batch\n",
    "\n",
    "\n",
    "x_filenames = tf.train.match_filenames_once(x_path_pattern)\n",
    "y_filenames = tf.train.match_filenames_once(y_path_pattern)\n",
    "\n",
    "batch_size = tf.Variable(initial_value=64, trainable=False, dtype=tf.int32)\n",
    "batch = input_pipeline(x_filenames, y_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the Session and the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase with Full Journalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "past_epochs = 0\n",
    "n_epochs = 150\n",
    "l_rate = 1e-3\n",
    "b_size = 5\n",
    "verbose = True\n",
    "sess_output_path = '{}{}_{}_{}-{}.txt'.format('/home/theskyabove/sessions/epoch_info/output_', arch_info, \n",
    "                                     l_rate, past_epochs, past_epochs + n_epochs)\n",
    "sess_checkpoint_path = '{}{}_{}_{}'.format('/home/theskyabove/sessions/session_', arch_info, \n",
    "                                     l_rate, past_epochs + n_epochs)\n",
    "sess_images_path = '{}_{}_{}_'.format(arch_info, l_rate, past_epochs + n_epochs)\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    epoch_time = time.time()\n",
    "    for i in range(800):\n",
    "        [x_batch, y_batch] = sess.run(batch, feed_dict={batch_size: b_size})\n",
    "        sess.run(optimizer, feed_dict={\n",
    "                X: x_batch,\n",
    "                Y_clear: y_batch,\n",
    "                learning_rate: l_rate,\n",
    "                batch_size: b_size\n",
    "            })\n",
    "    \n",
    "    loss = []\n",
    "    loss_2 = []\n",
    "    for i in range(1, 6, 1):\n",
    "        [a, b] = sess.run([cost, cost_2], feed_dict={X: testX[(i-1):i], Y_clear: testY[(i-1):i]})\n",
    "        loss += [a]\n",
    "        loss_2 += [b]\n",
    "    epoch_info = '{} {} {}\\n'.format(epoch_i + past_epochs, \n",
    "                                     [mean(loss), mean(loss_2)],\n",
    "                                     time.time() - epoch_time)\n",
    "    if verbose:\n",
    "        with open(sess_output_path, \"a\") as sess_output_file:\n",
    "            sess_output_file.write(epoch_info)\n",
    "    print(epoch_info)\n",
    "\n",
    "past_epochs += n_epochs \n",
    "if verbose:\n",
    "    saver.save(sess, sess_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Previously Saved Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, '/home/theskyabove/sessions/session_crs_ms-ssim_mse_mp_1024_16-32-64_5-5-5_0.99_0.0001_900')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "recon = []\n",
    "loss = []\n",
    "loss_2 = []\n",
    "for i in range(1, testX.shape[0] + 1, 1):\n",
    "    [c, a, b] = sess.run([Y, cost, cost_2], feed_dict={X: testX[(i-1):i], Y_clear: testY[(i-1):i]})\n",
    "    loss += [a]\n",
    "    loss_2 += [b]\n",
    "    recon += [c.reshape((size, size))]\n",
    "\n",
    "loss = mean(loss)\n",
    "loss_2 = mean(loss_2)\n",
    "orig = testX.reshape((-1, size, size))\n",
    "supp = testY.reshape((-1, size, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols = 5  # how many images we will display\n",
    "n_rows = 3\n",
    "plt.figure(figsize=(n_cols * n_rows, n_rows ** 2))\n",
    "for i in range(n_cols):\n",
    "    # display original\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.imshow(orig[i].reshape(size, size))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1 + n_cols)\n",
    "    plt.imshow((recon[i]).reshape(size, size)) #jrecon\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    if n_rows == 3:\n",
    "        # display bone-suppressed ground truth image\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1 + n_cols * 2)\n",
    "        plt.imshow((supp[i]).reshape(size, size))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "print(\"loss: %f\" %loss)\n",
    "plt.savefig('{}{}_{}.png'.format(sess_images_path, str(loss), str(loss_2)), \n",
    "            bbox_inches='tight', transparent=True, dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig = reshape(testX, (-1, size, size))\n",
    "path = 'tmp/to_test/'\n",
    "for i in range(len(recon)):\n",
    "    imsave(path + str(i) + 'orig.jpg', orig[i], cmap='gray')\n",
    "    imsave(path + str(i) + 'recon.jpg', recon[i], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
